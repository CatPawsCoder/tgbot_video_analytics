# Телеграм‑бот аналитики по видеоконтенту

Этот репозиторий содержит код телеграм‑бота, который по запросам на русском языке рассчитывает различные метрики по базе с итоговой и почасовой статистикой видео. Бот хранит данные в PostgreSQL, использует асинхронный стек (aiogram для бота, asyncpg для БД) и обращается к внешней LLM‑модели для преобразования естественного языка в SQL‑запросы.

## Состав проекта

```
video_analytics_bot/
├── Dockerfile              # сборка образа приложения
├── docker-compose.yml      # поднятие Postgres и бота в контейнерах
├── requirements.txt        # список зависимостей
├── .env.example            # пример файла с переменными окружения
├── migrations/
│   └── 001_init.sql        # создание таблиц videos и video_snapshots
└── src/
    ├── __init__.py
    ├── bot.py              # точка входа для бота
    ├── config.py           # загрузка настроек из окружения
    ├── db.py               # работа с PostgreSQL
    ├── load_data.py        # загрузка JSON‑файла в БД
    └── nlp.py              # обращение к LLM для построения SQL
```

### Основные компоненты

* **База данных** — две таблицы: `videos` (итоговая статистика по ролику) и `video_snapshots` (почасовые замеры). Описание схемы соответствует заданию: поля идентификаторов, дат публикации и замеров, итоговые счётчики и приращения. Скрипт для создания таблиц лежит в `migrations/001_init.sql`.

* **Загрузка данных** — модуль `src/load_data.py` содержит асинхронную функцию, которая принимает путь к исходному JSON‑файлу и заполняет БД. Структура файла предполагается аналогичной тому, что выдаётся в тестовом задании: массив объектов с полями итоговой статистики и вложенным списком снапшотов. Запуск скрипта: `python -m src.load_data path/to/data.json`.

* **Преобразование запросов** — в `src/nlp.py` описан промпт и функция, которая отправляет вопросы пользователей к LLM‑модели (например, OpenAI ChatGPT). Она получает текст запроса, добавляет описание схемы БД и просит модель вернуть корректный SQL. Возвращается только текст запроса, который затем выполняется через asyncpg. В примере используется модель `gpt-3.5-turbo`; вы можете заменить её или подключить локальную модель.

* **Телеграм‑бот** — файл `src/bot.py` реализует простую логику: при получении текстового сообщения бот вызывает `query_to_sql`, выполняет получившийся запрос и возвращает пользователю одно числовое значение. Бот не хранит состояние диалога; каждый запрос обрабатывается изолированно. Aiogram v3 используется для асинхронного polling.

## Запуск с Docker

1. Создайте `.env` по образцу `.env.example` и укажите в нём:
   * `BOT_TOKEN` — токен вашего телеграм‑бота от `@BotFather`.
   * `DATABASE_URL` — строку подключения к Postgres вида `postgresql+asyncpg://user:password@db:5432/dbname`.
   * `OPENAI_API_KEY` — ключ доступа к используемой LLM‑платформе. При желании можете использовать локальную модель — тогда в `src/nlp.py` замените вызов API на нужную реализацию.

2. Поднимите сервисы:

   ```sh
   docker compose build
   docker compose up -d
   ```

   `docker-compose.yml` создаёт два контейнера: `db` с PostgreSQL и `bot` с кодом приложения. Миграция выполняется автоматически при старте контейнера бота.

3. Загрузите данные из JSON (один раз):

   ```sh
   docker compose exec bot python -m src.load_data /app/data/videos.json
   ```

   Предварительно положите ваш файл в каталог `data` рядом с `docker-compose.yml` или укажите путь внутри контейнера.

4. После загрузки отправляйте боту сообщения в Telegram — он ответит числовым результатом.

## Локальный запуск (без Docker)

1. Установите Python 3.10+ и PostgreSQL. Создайте базу данных и пользователя.
2. Скопируйте `.env.example` в `.env` и пропишите свои значения.
3. Установите зависимости:

   ```sh
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

4. Выполните миграции:

   ```sh
   psql "postgresql://user:password@localhost:5432/dbname" -f migrations/001_init.sql
   ```

5. Загрузите данные:

   ```sh
   python -m src.load_data path/to/data.json
   ```

6. Запустите бота:

   ```sh
   python -m src.bot
   ```

## Архитектура и подход

* **SQL‑ориентированный ответ.** Главной задачей бота является получение числовой метрики на основе естественного вопроса. Мы решаем это так: на основе заранее подготовленного промпта (описание схемы таблиц и правила составления запросов) LLM‑модель генерирует SQL‑выражение. Затем это выражение выполняется в базе, и результат (одно число) возвращается пользователю.

* **Ограничение контекста.** Бот не сохраняет историю диалога, поэтому каждый вопрос рассматривается изолированно. Это упрощает логику и делает вычисления независимыми.

* **Асинхронность.** Все операции — запросы к LLM, БД и Telegram API — выполняются асинхронно. Это позволяет обрабатывать несколько запросов параллельно и не блокировать event loop.

* **Расширяемость.** Если вы решите использовать другую LLM или добавить собственную логику парсинга запросов, всё сосредоточено в одном модуле `src/nlp.py`. Там же можно добавить примеры (few‑shot) для улучшения качества SQL‑генерации.

## Имитация коммитов

Если вам нужно показать историю развития проекта, вы можете разбить работу на несколько логических коммитов. Например:

1. Инициализация репозитория: структура каталогов, `requirements.txt`, заготовка `README.md`.
2. Реализация и миграция базы: написание SQL‑скриптов, модуль `db.py`.
3. Загрузчик данных: `load_data.py` и тестирование на небольшом примере.
4. Интеграция LLM: модуль `nlp.py` с промптами и вызовом модели.
5. Реализация Telegram‑бота: `bot.py`, подключение `aiogram` и общей логики обработки сообщений.
6. Докеризация: `Dockerfile`, `docker-compose.yml` и `.env.example`.

Эти коммиты позволят показать постепенное развитие проекта, а также дают читателю понимание, какие изменения в какой момент вносились.